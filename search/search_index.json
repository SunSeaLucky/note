{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"deepfake/experiment/main/","title":"\u5b9e\u9a8c","text":""},{"location":"deepfake/experiment/main/#sepmark","title":"SepMark","text":""},{"location":"deepfake/experiment/main/#_1","title":"\u5b9e\u9a8c\u76ee\u7684","text":"<p>\u672c\u6b21\u5b9e\u9a8c\u9700\u9a8c\u8bc1\u4e09\u70b9\uff1a</p> <ul> <li>\u53cc\u91cd\u6c34\u5370\u653b\u51fb\u662f\u6709\u6548\u7684\uff0c\u5373\u5bf9\u4e8e\u540c\u4e00\u5f20\u56fe\u7247\uff0c\u7b2c\u4e8c\u6b21\u7f16\u7801\u5c06\u4f7f\u5f97\u7b2c\u4e00\u6b21\u7f16\u7801\u7684\u4fe1\u606f\u6d88\u5931\uff1b</li> <li>\u63d0\u51fa Loss \u7ea6\u675f\u662f\u6709\u6548\u7684\uff0c\u5373\u80fd\u591f\u89e3\u51b3\u53cc\u91cd\u6c34\u5370\u653b\u51fb\uff1b</li> <li>\u90e8\u5206\u5fae\u8c03\u662f\u53ef\u884c\u7684\uff0c\u6216\u8005\u8bf4\u4ec5\u9488\u5bf9\u89e3\u7801\u5668\u5fae\u8c03\u3001\u800c\u4e0d\u8fdb\u884c\u5168\u91cf\u5fae\u8c03\u662f\u53ef\u884c\u7684\uff1b</li> </ul>"},{"location":"deepfake/experiment/main/#_2","title":"\u5b9e\u9a8c\u7ed3\u679c","text":"<ul> <li>\u65e0\u5fae\u8c03/\u5fae\u8c03\u5bf9\u6bd4</li> </ul> g_loss error_rate_C error_rate_R error_rate_F psnr ssim g_loss_on_discriminator g_loss_on_encoder_MSE g_loss_on_encoder_LPIPS g_loss_on_decoder_C g_loss_on_decoder_R g_loss_on_decoder_F d_loss g_loss_on_double_watermark double_error_rate_C double_error_rate_R double_error_rate_F \u672a\u5fae\u8c03\uff08Epoch 100\uff09 1.1644 0.00691318 0.000124139 0.478008 38.7788 0.938527 2.03329 0.000531517 0.00808962 0.000523669 0.000302436 1.08015e-06 2.00961 0.114804 0.498312 0.500698 0.487456 \u5fae\u8c03\uff08Epoch 100\uff09 0.0316224 0.00481385 6.89663e-05 0.485183 38.3354 0.929688 2.12371 0.000589209 0.00874837 0.000439849 0.000251798 5.70558e-07 1.95333 0.00159519 0.00129381 0 0.493148"},{"location":"deepfake/experiment/main/#_3","title":"\u5b9e\u9a8c\u8fc7\u7a0b","text":"<p>\u5728 <code>network/Dual_Mark.py</code> \u7684\u7b2c 200 \u884c\u5de6\u53f3\uff0c\u6dfb\u52a0\u5982\u4e0b\u635f\u5931\u884c\uff1a</p> <pre><code># ======================= Double watermarking ====================== #\ndouble_message = torch.Tensor(np.random.choice([-1.0, 1.0], (images.shape[0], 128))).to('cuda')\ndouble_encoded_images, double_noised_images, double_decoded_messages_C, double_decoded_messages_R, double_decoded_messages_F = self.encoder_decoder(encoded_images, double_message, masks)\ng_loss_on_double_watermark = (\n    self.criterion_MSE(double_encoded_images, encoded_images) + \n    self.criterion_MSE(double_decoded_messages_C, decoded_messages_C)*5 + \n    self.criterion_MSE(double_decoded_messages_R, decoded_messages_R) + \n    self.criterion_MSE(double_decoded_messages_F, decoded_messages_F)\n</code></pre> <p>\u6dfb\u52a0 Loss \u540e\uff0c\u4ece Epoch 91 \uff08\u5305\u542b Epoch 91\uff09\u8bad\u7ec3\u81f3 Epoch 100\u3002\u5728\u6d4b\u8bd5\u96c6\u4e0a error_rate_C \u4f9d\u7136\u5728 50% \u9644\u8fd1\uff0c\u8fd9\u8bf4\u660e\u8be5 Loss \u4f3c\u4e4e\u6ca1\u6709\u4f5c\u7528\uff08\u540e\u53d1\u73b0\u5b9e\u9645\u4e0a\u662f\u56e0\u4e3a\u6d4b\u8bd5\u4ee3\u7801\u6709\u95ee\u9898\uff0c\u4e14\u672a\u627e\u51fa\u6d4b\u8bd5\u4ee3\u7801\u51fa\u95ee\u9898\u7684\u539f\u56e0\u3002\u5b9e\u9645\u4e0a\uff0c\u4e0d\u7ba1\u662f\u4e0d\u662f\u7531\u4e8e\u6d4b\u8bd5\u4ee3\u7801\u6709\u95ee\u9898\uff0c\u8fd9\u91cc\u7684 Loss \u8fd9\u4e48\u5199\u90fd\u662f\u4e0d\u5408\u9002\u7684\uff0c\u5e94\u5f53\u5148\u6309\u7167\u4e0b\u9762\u7684\u65b9\u5f0f\u91cd\u65b0\u5199 Loss\uff09\u3002</p> <p>\u731c\u6d4b\u5931\u8d25\u539f\u56e0\uff1a\u7ea6\u675f\u7b2c\u4e00\u6b21\u89e3\u7801\u4fe1\u606f\u548c\u7b2c\u4e8c\u6b21\u89e3\u7801\u4fe1\u606f\u76f8\u540c\uff0c\u4f46\u7b2c\u4e00\u6b21\u89e3\u7801\u4fe1\u606f\u672c\u8eab\u53c8\u4e0d\u4e00\u5b9a\u51c6\u786e\u3002</p> <p>\u89e3\u51b3\u65b9\u6848\uff1a\u7ea6\u675f\u7b2c\u4e00\u6b21 \u7f16\u7801 \u4fe1\u606f\u548c\u7b2c\u4e8c\u6b21\u89e3\u7801\u4fe1\u606f\u76f8\u540c\uff0c\u540c\u65f6\u8d4b\u4e88\u6743\u91cd\u3002\u628a\u6dfb\u52a0\u7684 Loss \u4fee\u6539\u4e3a\uff1a</p> <pre><code>double_message = torch.Tensor(np.random.choice([-1.0, 1.0], (images.shape[0], 128))).to('cuda')\ndouble_encoded_images, double_noised_images, double_decoded_messages_C, double_decoded_messages_R, double_decoded_messages_F = self.encoder_decoder(encoded_images, double_message, masks)\ng_loss_on_double_watermark = (\n    self.criterion_MSE(double_encoded_images, encoded_images) + \n    self.criterion_MSE(double_decoded_messages_C, messages)*5 + \n    self.criterion_MSE(double_decoded_messages_R, messages) + \n    self.criterion_MSE(double_decoded_messages_F, torch.zeros_like(messages))\n)\n</code></pre> <p>\u8bad\u7ec3\u7ed3\u675f\u540e\uff0c\u4fee\u6539 <code>test_Dual_Mark.py</code> \u4ee3\u7801\uff0c\u4f7f\u5176\u7f16\u7801\u4e24\u6b21\u6c34\u5370\uff0c\u8fd0\u884c\u5f97\u5230\u7684 error_rate_C \u4f9d\u7136\u5f88\u9ad8\uff0850% \u5de6\u53f3\u6d6e\u52a8\uff09\u3002\u4f46\u662f\u5982\u679c\u501f\u52a9\u6a21\u578b\u7684 <code>validation()</code> \u51fd\u6570\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fd0\u884c\uff0c\u5219\u7ed3\u679c\u6b63\u5e38\uff1a</p> <pre><code>with tqdm(total=len(val_dataloader)) as pbar:\n    for step, (image, mask) in enumerate(val_dataloader, 1):\n        image = image.to(device)\n        message = torch.Tensor(np.random.choice([-message_range, message_range], (image.shape[0], message_length))).to(device)\n\n        result_origin, (images, encoded_images, noised_images) = network_origin.validation(image, message, mask)\n        result_double_watermark, (images, encoded_images, noised_images) = network_double_watermark.validation(image, message, mask)\n\n        for key in result_origin:\n            test_result_origin[key] += float(result_origin[key])\n            test_result_double_watermark[key] += float(result_double_watermark[key])\n\nfor key in result_origin:\n    test_result_origin[key] /= len(val_dataloader)\n    test_result_double_watermark[key] /= len(val_dataloader)\npd.DataFrame([test_result_origin, test_result_double_watermark], index=[0]).to_markdown(\"test_result.md\")\n</code></pre> <p>\u731c\u6d4b\u662f <code>test_Dual_Mark.py</code> \u4ee3\u7801\u7684\u95ee\u9898\uff0c\u6682\u672a\u627e\u5230\u539f\u56e0\u3002\u4e0d\u8fc7\u597d\u5728\u7ec8\u4e8e\u53ef\u4ee5\u5728\u6d4b\u8bd5\u96c6\u4e0a\u68c0\u9a8c\u5fae\u8c03\u6548\u679c\uff0c\u6682\u65f6</p>"},{"location":"ict/main/","title":"ICT \u5b9e\u9a8c\u7b14\u8bb0","text":""},{"location":"ict/main/#2024-mindspore","title":"2024 \u5e74\u56fd\u8d5b\u8bd5\u9898 MindSpore \u90e8\u5206\u5185\u5bb9\u7814\u7a76","text":""},{"location":"ict/main/#_1","title":"\u4efb\u52a1\u4e00","text":"<p>\u4e3b\u8981\u76ee\u7684\u662f\u8bad\u7ec3\u4e00\u4e2a\u53ef\u4ee5\u8bc6\u522b\u5f00\u53d1\u677f\u4e0a\u80fd\u591f\u6807\u51fa\u84dd\u8272\u533a\u57df\u7684\u6a21\u578b\u3002</p> <p></p> <ul> <li>\u8003\u70b9\u4e00 \u5b9e\u9a8c\u4e91\u73af\u5883\u51c6\u5907</li> </ul> <p>\u5373\u5728 ModelArts \u7684 Notebook \u4e0b\u8d2d\u4e70 Notebook \u5b9e\u4f8b\uff0c\u6309\u7167\u5176\u8981\u6c42\u914d\u7f6e\u73af\u5883\u3002</p> <ul> <li>\u8003\u70b9\u4e8c \u586b\u5199\u6570\u636e\u9884\u5904\u7406\u90e8\u5206\u7684\u7f3a\u5931\u4ee3\u7801</li> </ul> <p>\u9884\u8bf4\u660e\u7684\u90e8\u5206</p> <p>\u5b9e\u9a8c\u6570\u636e\u96c6\u5206\u4e3a\u539f\u59cb\u6570\u636e\u96c6\u548c\u9884\u5904\u7406\u540e\u7684\u6570\u636e\u96c6</p> <ul> <li>\u539f\u59cb\u6570\u636e\u96c6\u4e3a raw data\uff0c\u5c5e\u4e8e coco \u683c\u5f0f\u6570\u636e\u96c6\uff0c\u5305\u542b\u56fe\u7247 image \u4ee5\u53ca annotation \u6587\u4ef6\u3002\u539f\u59cb\u6570\u636e\u96c6\u4e0d\u80fd\u76f4\u63a5\u4f7f\u7528\uff0c\u9700\u8981\u7ecf\u8fc7\u6570\u636e\u9884\u5904\u7406\u3002</li> <li>\u9884\u5904\u7406\u540e\u7684\u6570\u636e\u96c6\u4e3a data\uff0c\u5b58\u653e\u9884\u5904\u7406\u540e\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b\u56fe\u7247 image \u548c\u6807\u7b7e mask\uff0c\u7528\u4e8e\u6a21\u578b\u8bad\u7ec3\u548c\u63a8\u7406\u3002</li> </ul> <p>raw_data \u7684\u76ee\u5f55\u7ed3\u6784\uff1a</p> <p></p> <p>\u9996\u5148\u662f\u586b\u5199 <code>preprocess_dataset.py</code> \u7684\u4e09\u5904\u7a7a\u7f3a\u3002\u7b2c\u4e00\u5904\u7a7a\u7f3a\u5982\u4e0b\uff1a</p> <pre><code>#1\u3001\u586b\u5199\u53c2\u6570\u6807\u7b7e\n#------------------**************\nanno_json =   # annotaion json\u6587\u4ef6\u8def\u5f84\ncoco_cls =   # \u6570\u636e\u7c7b\u522b80+1\u7c7b\u7684\u540d\u5b57\ncoco_dir =   # \u6570\u636e\u96c6\u8def\u5f84\nsave_dir =   # \u6700\u7ec8\u7ed3\u679c\u4fdd\u5b58\u8def\u5f84    \n#--------------------***********************\n</code></pre> <pre><code>if __name__ == '__main__':\n    parser = argparse.ArgumentParser(description='Train the UNet on images and target masks',\n                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n    parser.add_argument('-d', '--data_url', dest='data_url', type=str, default='data/',\n                        help='save data directory')\n    args = parser.parse_args()\n    preprocess_dataset(cfg_unet, args.data_url)\n</code></pre> <p>\u53ef\u4ee5\u770b\u5230\u7a0b\u5e8f\u9996\u5148\u6267\u884c\u5230 <code>preprocess_dataset()</code> \u51fd\u6570\uff0c\u5982\u4e0b\uff1a</p> <pre><code>def preprocess_dataset(cfg, data_dir):\n    \"\"\"Select preprocess function.\"\"\"\n    if cfg['dataset'].lower() == \"cell_nuclei\":\n        preprocess_cell_nuclei_dataset({\"data_dir\": data_dir})\n    elif cfg['dataset'].lower() == \"coco\":\n        if 'split' in cfg and cfg['split'] == 1.0:\n            train_data_path = os.path.join(data_dir, \"train\")\n            val_data_path = os.path.join(data_dir, \"val\")\n            train_param_dict = {\"anno_json\": cfg[\"anno_json\"], \"coco_classes\": cfg[\"coco_classes\"],\n                                \"coco_dir\": cfg[\"coco_dir\"], \"save_dir\": train_data_path}\n            preprocess_coco_dataset(train_param_dict)\n            val_param_dict = {\"anno_json\": cfg[\"val_anno_json\"], \"coco_classes\": cfg[\"coco_classes\"],\n                              \"coco_dir\": cfg[\"val_coco_dir\"], \"save_dir\": val_data_path}\n            preprocess_coco_dataset(val_param_dict)\n        else:\n            param_dict = {\"anno_json\": cfg[\"anno_json\"], \"coco_classes\": cfg[\"coco_classes\"],\n                          \"coco_dir\": cfg[\"coco_dir\"], \"save_dir\": data_dir}\n            preprocess_coco_dataset(param_dict)\n    else:\n        raise ValueError(\"Not support dataset mode {}\".format(cfg['dataset']))\n    print(\"========== end preprocess dataset ==========\")\n</code></pre> <p>\u7531\u4e8e\u9898\u76ee\u8bf4\u6570\u636e\u96c6\u662f coco \u683c\u5f0f\uff0c\u6240\u4ee5\u7a0b\u5e8f\u4f1a\u6267\u884c <code>preprocess_coco_dataset()</code> \u4f1a\u5206\u522b\u4ee5 train_param_dict\u3001val_param_dict\u3001param_dict \u4f5c\u4e3a\u53c2\u6570\u8c03\u7528\u3002</p> <p>\u7531\u6b64\u5df2\u7ecf\u53ef\u4ee5\u660e\u786e\u51fd\u6570 <code>preprocess_coco_dataset()</code> \u7684\u53c2\u6570\u662f dict() \u7c7b\u578b\uff0c\u6240\u4ee5\u7b2c\u4e00\u4e2a\u7f3a\u5931\u7b54\u6848\u5982\u4e0b\uff1a</p> <pre><code>#1\u3001\u586b\u5199\u53c2\u6570\u6807\u7b7e\n#------------------**************\nanno_json = param_dict[\"anno_json\"]   # JSON\u683c\u5f0f\u6807\u6ce8\u6587\u4ef6\u8def\u5f84\ncoco_cls = param_dict[\"coco_classes\"] # \u6570\u636e\u7c7b\u522b80+1\u7c7b\u7684\u540d\u5b57\ncoco_dir = param_dict[\"coco_dir\"]     # \u6570\u636e\u96c6\u8def\u5f84\nsave_dir = param_dict[\"save_dir\"]     # \u6700\u7ec8\u7ed3\u679c\u4fdd\u5b58\u8def\u5f84\n#--------------------***********************\n</code></pre> <p>\u7b2c\u4e8c\u5904\u7a7a\u7f3a\u5982\u4e0b\uff1a</p> <pre><code>coco_cls_dict = {}  # key\u4e3a\u7c7b\u540d\uff0cvalue\u4e3a\u7d22\u5f15\u503c\nfor i, cls in enumerate(coco_cls):\n\n    # 2\u3001\u8865\u5168\u8be5\u5904\u4ee3\u7801\n    #------------------**************    \n    coco_cls_dict[xxx] =   # eg:{'backgroud':0, 'person':1',...}\n    #------------------**************\n</code></pre> <p>\u586b\u7a7a 1 \u5904\uff0c\u8bf4 coco_cls \u662f \u6570\u636e\u7c7b\u522b80+1\u7c7b\u7684\u540d\u5b57\uff0c\u904d\u5386\u53d8\u91cf\u4e2d\uff0ci \u9010\u6e10\u9012\u589e\uff0ccls (class \u7684\u7f29\u5199) \u662f\u7c7b\u522b\u540d\u3002</p> <p>\u9700\u8981\u8865\u5168\u5904\u7684\u6ce8\u91ca\u53c8\u8bf4\u660e key-value \u4e2d\u7684 key \u5e94\u8be5\u662f\u540d\u5b57\uff0c\u800c\u7b49\u4e8e\u7684\u503c\u53c8\u662f\u6570\u5b57\uff0c\u6240\u4ee5\u5e94\u8be5\u662f <code>coco_cls_dict[cls] = i</code>\u3002\u6240\u4ee5\u7b2c\u4e8c\u5904\u7f3a\u5931\u7b54\u6848\u5982\u4e0b\uff1a</p> <pre><code># 2\u3001\u8865\u5168\u8be5\u5904\u4ee3\u7801\n#------------------**************\ncoco_cls_dict[xxx] =   # eg:{'backgroud':0, 'person':1',...}\n#------------------**************\n</code></pre> <p>\u7b2c\u4e09\u5904\u7a7a\u7f3a\u5982\u4e0b\uff1a</p> <pre><code>#3\u3001\u8865\u5168\u8be5\u5904\u4ee3\u7801\n#------------------**************\nfor instance in anno:\n    m = annToMask(   )  # h*w\u7684array\n    c = coco_cls_dict[ ]  # \u6700\u91cc\u5c42\u4e3a\u6b64\u5206\u5272\u7269\u4f53\u5c5e\u4e8e\u54ea\u7c7b\u3002class_dict\u628aidx\u8f6c\u6210\u7c7b\u540d\uff0ccls_dict\u628a\u7c7b\u540d\u8f6c\u56deidx\n    if len(m.shape) &lt; 3:\n        mask[:, :] += () * ( * )  # \u5f53\u524d\u5c5e\u4e8e\u80cc\u666f\u7684mask=0\uff0c\u4e0e\u5f97\u5230\u7684\u7269\u4f53\u7684\u77e9\u9635m\uff0c\u5bf9\u5e94\u4f4d\u7f6e\u4e0a\u6807\u8bb0\u4e3a\u7c7b\u522bc\n    else:\n        mask[:, :] += () * (((  * c).astype(np.uint8)  # \u5c063d\u8f6c\u62102d,\u505a\u4e0a\u9762\u7c7b\u4f3c\u7684\u64cd\u4f5c\n#------------------**************\n</code></pre> <p>\u7b2c\u4e00\u4e2a\u51fd\u6570 annToMask() \u610f\u601d\u5373\u5c06\u6807\u6ce8\u8f6c\u5316\u4e3a mask\uff0c\u51fd\u6570\u4f53\u5982\u4e0b\uff1a</p> <pre><code>def annToMask(ann, height, width):\n    \"\"\"Convert annotation to RLE and then to binary mask.\"\"\"\n    from pycocotools import mask as maskHelper\n    segm = ann['segmentation']  # \u524d\u666f\u8fb9\u754c\u70b9\uff0c\u5bf9\u5e94coco rle\u683c\u5f0f\n    if isinstance(segm, list):\n        rles = maskHelper.frPyObjects(segm, height, width)\n        rle = maskHelper.merge(rles)\n    elif isinstance(segm['counts'], list):\n        rle = maskHelper.frPyObjects(segm, height, width)\n    else:\n        rle = ann['segmentation']\n    m = maskHelper.decode(rle)\n    return m\n</code></pre> <p>\u5373\u51fd\u6570 annToMask() \u8f93\u5165\u6807\u6ce8 ann\uff0cheight \u548c width\uff0c\u8f93\u51fa mask\u3002\u7531\u4e8e for \u5faa\u73af\u91cc\u904d\u5386\u53d8\u91cf\u4e3a instance\uff0c\u6240\u4ee5\u786e\u5b9a\u7b2c\u4e00\u4e2a\u53c2\u6570\u5e94\u8be5\u662f\u6807\u6ce8\uff0c\u5373 instance\u3002\u540e\u9762\u7684\u9ad8\u548c\u5bbd\uff0c\u53ef\u4ee5\u770b\u5230\u524d\u9762\u51e0\u884c\u6709\u53d8\u91cf h \u548c w \u7684\u8d4b\u503c\uff0c\u8fd9\u91cc\u9664\u4e86\u586b\u5b83\u4fe9\u4e5f\u6ca1\u4ec0\u4e48\u522b\u7684\u53ef\u586b\u7684\u4e86\uff0c\u56e0\u6b64\u7b2c 4 \u884c\u7b54\u6848\u662f <code>m = annToMask(instance, h, w)</code>\u3002</p> <p>\u7b2c 5 \u884c\u7ed9\u51fa\u7684\u63d0\u793a\u8bf4\uff1aclass_dict\u628aidx\u8f6c\u6210\u7c7b\u540d\uff0ccls_dict\u628a\u7c7b\u540d\u8f6c\u56deidx\u3002\u540c\u65f6\uff0c\u501f\u52a9\u4ee3\u7801\u8865\u5168\u63d2\u4ef6 FittenCode\uff0c\u7ed9\u51fa\u7684\u63d0\u793a\u4e3a <code>classs_dict[instance[\"category_id\"]]</code>\u3002\u731c\u6d4b\u6211\u4eec\u9700\u8981\u77e5\u9053 instance \u5bf9\u5e94 json \u6587\u4ef6\u7684\u952e\u503c\uff0c\u6253\u5f00 <code>raw_data/annotations/instances_annotations.json</code>\uff0c\u5982\u4e0b\uff1a</p> <p></p> <p>\u8fd9\u8bf4\u660e AI \u7ed9\u51fa\u7684\u63d0\u793a\u51c6\u786e\u65e0\u8bef\uff0c\u5373\u7b2c 5 \u884c\u7b54\u6848\u4e3a\uff1a<code>c = coco_cls_dict[instance[\"category_id\"]]</code>\u3002</p> <p>\u7b2c\u4e09\u5904\u7a7a\u7f3a\u8fd8\u5269</p>"},{"location":"ict/main/#_2","title":"\u5b9e\u8df5\u6848\u4f8b","text":""},{"location":"ict/main/#_3","title":"\u8ba1\u7b97\u673a\u89c6\u89c9","text":""},{"location":"ict/main/#resnet-50","title":"ResNet 50 \u56fe\u50cf\u5206\u7c7b","text":"<p>ReNet \u4e3b\u8981\u89e3\u51b3\u7684\u95ee\u9898\uff1a\u51cf\u8f7b\u7f51\u7edc\u5c42\u6570\u589e\u52a0\u65f6\uff0c\u6a21\u578b\u7684\u9000\u5316\u95ee\u9898\u3002\u5927\u81f4\u7ed3\u6784\u5982\u4e0b\uff1a</p> <p></p> <p>ResNet \u6709\u4e24\u79cd\u7f51\u7edc\u7ed3\u6784\uff0c\u4e00\u79cd\u662f Building Block\uff0c\u4e00\u79cd\u662f Bottleneck Block\u3002Building Block \u5927\u81f4\u7ed3\u6784\u5982\u4e0b\uff1a</p> <p></p> <p>Bottleneck Block \u5927\u81f4\u7ed3\u6784\u5982\u4e0b\uff1a</p> <p></p>"},{"location":"ict/main/#vision-transformer","title":"Vision Transformer","text":"<p>Transformer \u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6a21\u578b\u7684\u53d1\u5c55\u7ed3\u6676\uff0cViT \u5219\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u4e24\u4e2a\u9886\u57df\u7684\u7ed3\u6676\u3002\u5728\u4e0d\u4f9d\u8d56\u5377\u79ef\u64cd\u4f5c\u7684\u60c5\u51b5\u4e0b\uff0c\u4ecd\u80fd\u8fbe\u5230\u8f83\u597d\u7684\u6548\u679c\u3002</p> <p>ViT \u7684\u4e3b\u4f53\u7ed3\u6784\uff1a</p> <p></p> <p>\u5148\u89e3\u91ca Transformer \u7684\u57fa\u672c\u539f\u7406\u3002\u4e0b\u56fe\u4e2d\u7684\u7f51\u7edc\u7ed3\u6784\u662f\u7531 Transformer \u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u7ec4\u6210\u7684\uff1a</p> <p></p> <p>\u5176\u4e2d\u7684\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u8be6\u7ec6\u7ed3\u6784\u5982\u4e0b\uff1a</p> <p></p> <p>\u8fd9\u5176\u4e2d\u6700\u91cd\u8981\u7684\u5c31\u662f Multi-Head Attention\uff0c\u8be5\u7ed3\u6784\u57fa\u4e8e\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u662f\u591a\u4e2a Self-Attention \u7684\u5e76\u884c\u7ec4\u6210\u3002\u7406\u89e3 Self-Attention \u5c31\u6293\u4f4f\u4e86 Transformer \u7684\u6838\u5fc3\u3002</p> <p>Self-Attention \u7684\u6838\u5fc3\u5185\u5bb9\u662f\u4e3a\u8f93\u5165\u5411\u91cf\u7684\u6bcf\u4e2a\u5355\u8bcd\u5b66\u4e60\u4e00\u4e2a\u6743\u91cd\u3002</p>"}]}
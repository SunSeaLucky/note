{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"deepfake/experiment/main/","title":"\u5b9e\u9a8c","text":""},{"location":"deepfake/experiment/main/#sepmark","title":"SepMark","text":""},{"location":"deepfake/experiment/main/#_1","title":"\u5b9e\u9a8c\u76ee\u7684","text":"<p>\u672c\u6b21\u5b9e\u9a8c\u9700\u9a8c\u8bc1\u4e09\u70b9\uff1a</p> <ul> <li>\u53cc\u91cd\u6c34\u5370\u653b\u51fb\u662f\u6709\u6548\u7684\uff0c\u5373\u5bf9\u4e8e\u540c\u4e00\u5f20\u56fe\u7247\uff0c\u7b2c\u4e8c\u6b21\u7f16\u7801\u5c06\u4f7f\u5f97\u7b2c\u4e00\u6b21\u7f16\u7801\u7684\u4fe1\u606f\u6d88\u5931\uff1b</li> <li>\u63d0\u51fa Loss \u7ea6\u675f\u662f\u6709\u6548\u7684\uff0c\u5373\u80fd\u591f\u89e3\u51b3\u53cc\u91cd\u6c34\u5370\u653b\u51fb\uff1b</li> <li>\u90e8\u5206\u5fae\u8c03\u662f\u53ef\u884c\u7684\uff0c\u6216\u8005\u8bf4\u4ec5\u9488\u5bf9\u89e3\u7801\u5668\u5fae\u8c03\u3001\u800c\u4e0d\u8fdb\u884c\u5168\u91cf\u5fae\u8c03\u662f\u53ef\u884c\u7684\uff1b</li> </ul>"},{"location":"deepfake/experiment/main/#_2","title":"\u5b9e\u9a8c\u8bb0\u5f55","text":""},{"location":"deepfake/experiment/main/#_3","title":"\u7b2c\u4e00\u6b21\u5b9e\u9a8c","text":"<p>\u5728 <code>network/Dual_Mark.py</code> \u7684\u7b2c 200 \u884c\u5de6\u53f3\uff0c\u6dfb\u52a0\u5982\u4e0b\u635f\u5931\u884c\uff1a</p> <pre><code># ======================= Double watermarking ====================== #\ndouble_message = torch.Tensor(np.random.choice([-1.0, 1.0], (images.shape[0], 128))).to('cuda')\ndouble_encoded_images, double_noised_images, double_decoded_messages_C, double_decoded_messages_R, double_decoded_messages_F = self.encoder_decoder(encoded_images, double_message, masks)\ng_loss_on_double_watermark = (\n    self.criterion_MSE(double_encoded_images, encoded_images) + \n    self.criterion_MSE(double_decoded_messages_C, decoded_messages_C)*5 + \n    self.criterion_MSE(double_decoded_messages_R, decoded_messages_R) + \n    self.criterion_MSE(double_decoded_messages_F, decoded_messages_F)\n</code></pre> <p>\u6dfb\u52a0 Loss \u540e\uff0c\u4ece Epoch 91 \uff08\u5305\u542b Epoch 91\uff09\u8bad\u7ec3\u81f3 Epoch 100\u3002\u5728\u6d4b\u8bd5\u96c6\u4e0a error_rate_C \u4f9d\u7136\u5728 50% \u9644\u8fd1\uff0c\u8fd9\u8bf4\u660e\u8be5 Loss \u4f3c\u4e4e\u6ca1\u6709\u4f5c\u7528\u3002</p> <p>\u731c\u6d4b\u5931\u8d25\u539f\u56e0\uff1a\u7ea6\u675f\u7b2c\u4e00\u6b21\u89e3\u7801\u4fe1\u606f\u548c\u7b2c\u4e8c\u6b21\u89e3\u7801\u4fe1\u606f\u76f8\u540c\uff0c\u4f46\u7b2c\u4e00\u6b21\u89e3\u7801\u4fe1\u606f\u672c\u8eab\u53c8\u4e0d\u4e00\u5b9a\u51c6\u786e\u3002</p> <p>\u89e3\u51b3\u65b9\u6848\uff1a\u7ea6\u675f\u7b2c\u4e00\u6b21 \u7f16\u7801 \u4fe1\u606f\u548c\u7b2c\u4e8c\u6b21\u89e3\u7801\u4fe1\u606f\u76f8\u540c\uff0c\u540c\u65f6\u8d4b\u4e88\u6743\u91cd\u3002</p>"},{"location":"deepfake/experiment/main/#_4","title":"\u7b2c\u4e8c\u6b21\u5b9e\u9a8c","text":"<p>\u628a\u6dfb\u52a0\u7684 Loss \u4fee\u6539\u4e3a\uff1a</p> <pre><code>double_message = torch.Tensor(np.random.choice([-1.0, 1.0], (images.shape[0], 128))).to('cuda')\ndouble_encoded_images, double_noised_images, double_decoded_messages_C, double_decoded_messages_R, double_decoded_messages_F = self.encoder_decoder(encoded_images, double_message, masks)\ng_loss_on_double_watermark = (\n    self.criterion_MSE(double_encoded_images, encoded_images) + \n    self.criterion_MSE(double_decoded_messages_C, messages)*5 + \n    self.criterion_MSE(double_decoded_messages_R, messages) + \n    self.criterion_MSE(double_decoded_messages_F, torch.zeros_like(messages))\n)\n</code></pre> <p>\u8bad\u7ec3\u7ed3\u675f\u540e\uff0c\u4fee\u6539 <code>test_Dual_Mark.py</code> \u4ee3\u7801\uff0c\u4f7f\u5176\u7f16\u7801\u4e24\u6b21\u6c34\u5370\uff0c\u8fd0\u884c\u5f97\u5230\u7684 error_rate_C \u4f9d\u7136\u5f88\u9ad8\uff0850% \u5de6\u53f3\u6d6e\u52a8\uff09\u3002\u4f46\u662f\u5982\u679c\u501f\u52a9\u6a21\u578b\u7684 <code>validation</code> \u51fd\u6570\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fd0\u884c\uff0c\u5219\u7ed3\u679c\u6b63\u5e38\uff1a</p> <pre><code>import yaml\nfrom easydict import EasyDict\nimport os\nimport time\nfrom shutil import copyfile\nimport random\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\nfrom network.Dual_Mark import *\nfrom utils import *\nfrom tqdm import tqdm\n\n\ndef seed_torch(seed=42):\n    seed = int(seed)\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.enabled = True\n\n\ndef main():\n    # ========================== Init network ========================== #\n    network = Network(message_length, noise_layers_R, noise_layers_F, device, batch_size, lr, beta1, attention_encoder, attention_decoder, weight)\n    if args.resume_config.resume:\n        network.load_model(\n            args.resume_config.encoder_decoder_model_path, \n            args.resume_config.discriminator_model_path, \n        )\n\n    # ========================== Init dataset ========================== #\n    train_dataset = attrsImgDataset(train_dataset_path, image_size, \"celebahq\")\n    #train_dataset = maskImgDataset(os.path.join(dataset_path, \"train_\" + str(image_size)), image_size)\n    assert len(train_dataset) &gt; 0, \"train dataset is empty\"\n    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n\n    val_dataset = attrsImgDataset(val_dataset_path, image_size, \"celebahq\")\n    assert len(val_dataset) &gt; 0, \"val dataset is empty\"\n    #val_dataset = maskImgDataset(os.path.join(dataset_path, \"val_\" + str(image_size)), image_size)\n    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n\n    # =========================== Train &amp; Val ========================== #\n    print(\"\\nStart training : \\n\\n\")\n\n\n    # =========================== Validation =========================== #\n    val_result = {\n        \"g_loss\": 0.0,\n        \"error_rate_C\": 0.0,\n        \"error_rate_R\": 0.0,\n        \"error_rate_F\": 0.0,\n        \"psnr\": 0.0,\n        \"ssim\": 0.0,\n        \"g_loss_on_discriminator\": 0.0,\n        \"g_loss_on_encoder_MSE\": 0.0,\n        \"g_loss_on_encoder_LPIPS\": 0.0,\n        \"g_loss_on_decoder_C\": 0.0,\n        \"g_loss_on_decoder_R\": 0.0,\n        \"g_loss_on_decoder_F\": 0.0,\n        \"d_loss\": 0.0,\n        # ==================== Added double watermarking =================== #\n        \"g_loss_on_double_watermark\": 0.0, \n        \"double_error_rate_C\": 0.0,\n        \"double_error_rate_R\": 0.0,\n        \"double_error_rate_F\": 0.0\n    }\n    start_time = time.time()\n\n    saved_iterations = np.random.choice(np.arange(1, len(val_dataloader)+1), size=save_images_number, replace=False)\n    saved_all = None\n\n    for step, (image, mask) in enumerate(val_dataloader, 1):\n        image = image.to(device)\n        message = torch.Tensor(np.random.choice([-message_range, message_range], (image.shape[0], message_length))).to(device)\n\n        result, (images, encoded_images, noised_images) = network.validation(image, message, mask)\n        print(f\"error rate C: {result['error_rate_C']:.4f}, error rate R: {result['error_rate_R']:.4f}, error rate F: {result['error_rate_F']:.4f}, psnr: {result['psnr']:.4f}, ssim: {result['ssim']:.4f}\")\n        print(f\"double error rate C: {result['double_error_rate_C']:.4f}, double error rate R: {result['double_error_rate_R']:.4f}, double error rate F: {result['double_error_rate_F']:.4f}\")\n\n        for key in result:\n            val_result[key] += float(result[key])\n\nif __name__ == '__main__':\n    seed_torch(42) # it does not work if the mode of F.interpolate is \"bilinear\"\n    # ======================= Init configuration ======================= #\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"\\nUsing device: {device}\")\n    with open('cfg/train_DualMark.yaml', 'r') as f:\n        args = EasyDict(yaml.load(f, Loader=yaml.SafeLoader))\n    project_name = args.project_name\n    epoch_number = args.epoch_number\n    batch_size = args.batch_size\n    lr = args.lr\n    beta1 = args.beta1\n    image_size = args.image_size\n    message_length = args.message_length\n    message_range = args.message_range\n    attention_encoder = args.attention_encoder\n    attention_decoder = args.attention_decoder\n    weight = args.weight\n    dataset_path = args.dataset_path\n    save_images_number = args.save_images_number\n    noise_layers_R = args.noise_layers.pool_R\n    noise_layers_F = args.noise_layers.pool_F    \n    train_dataset_path = os.path.join(dataset_path, \"train_\" + str(image_size))\n    # \u8fd9\u91cc\u7684val_dataset_path\u662f\u6d4b\u8bd5\u96c6\u7684\u8def\u5f84\uff0c\u4e0d\u662f\u9a8c\u8bc1\u96c6\u7684\u8def\u5f84\n    val_dataset_path = os.path.join(dataset_path, \"test_\" + str(image_size))\n\n    if noise_layers_R is None:\n        noise_layers_R = []\n    if noise_layers_F is None:\n        noise_layers_F = []\n    assert os.path.exists(train_dataset_path), \"train dataset is not exist\"\n    assert os.path.exists(val_dataset_path), \"val dataset is not exist\"\n\n    project_name += \"_\" + str(image_size) + \"_\" + str(message_length) + \"_\" + str(message_range) + \"_\" + str(lr) + \"_\" + str(beta1) + \"_\" + attention_encoder + \"_\" + attention_decoder\n    for i in weight:\n        project_name += \"_\" +  str(i)\n    result_folder = \"results/\" + time.strftime(project_name + \"_%Y_%m_%d_%H_%M_%S\", time.localtime()) + \"/\"\n    if not os.path.exists(result_folder): os.mkdir(result_folder)\n    if not os.path.exists(result_folder + \"images/\"): os.mkdir(result_folder + \"images/\")\n    if not os.path.exists(result_folder + \"models/\"): os.mkdir(result_folder + \"models/\")\n    copyfile(\"cfg/train_DualMark.yaml\", result_folder + \"train_DualMark.yaml\")\n    writer = SummaryWriter('runs/'+ project_name + time.strftime(\"%_Y_%m_%d__%H_%M_%S\", time.localtime()))\n    main()\n    writer.close()\n</code></pre> <p>\u731c\u6d4b\u662f <code>test_Dual_Mark.py</code> \u4ee3\u7801\u7684\u95ee\u9898\u3002\u6682\u672a\u627e\u5230\u539f\u56e0\u3002</p>"},{"location":"deepfake/experiment/main/#_5","title":"\u5b9e\u9a8c\u7ed3\u679c","text":"<p>\u8fd0\u884c <code>./board.sh</code>\uff0c\u5176\u4e2d </p> <pre><code>Dual_watermark_256_128_0.1_5e-05_0.5_se_se_1_10_10_10_0.1_2025_03_03_03_22_22\n</code></pre> <p>\u4e3a\u4fee\u6539\u4ee3\u7801\u540e\uff08\u7b2c\u4e8c\u6b21\u5b9e\u9a8c\uff09\u7684\u8fd0\u884c\u7b2c 91-100 \u8f6e\u7684\u8fc7\u7a0b\u3002</p>"}]}